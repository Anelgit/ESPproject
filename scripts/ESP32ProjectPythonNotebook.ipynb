{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "7uNuGx-zLoUx",
        "outputId": "39076766-307a-41d3-8310-13f98db17b6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7683ca91-4619-4784-9147-ffb9fb42b54d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7683ca91-4619-4784-9147-ffb9fb42b54d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset.zip to dataset.zip\n",
            "Extracted dataset to: dataset\n",
            "dataset 0 files\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import zipfile, os\n",
        "from google.colab import files\n",
        "\n",
        "# Upload dataset.zip from your computer\n",
        "uploaded = files.upload()   # <-- pick your dataset.zip here\n",
        "\n",
        "# Unzip into /content/dataset\n",
        "zip_path = list(uploaded.keys())[0]\n",
        "extract_dir = Path(\"dataset\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(extract_dir)\n",
        "\n",
        "print(\"Extracted dataset to:\", extract_dir)\n",
        "for cls in extract_dir.iterdir():\n",
        "    if cls.is_dir():\n",
        "        print(cls.name, len(list(cls.glob(\"*.wav\"))), \"files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Move dataset/dataset/* -> dataset/\n",
        "inner = Path(\"dataset/dataset\")\n",
        "outer = Path(\"dataset\")\n",
        "\n",
        "if inner.exists():\n",
        "    for sub in inner.iterdir():\n",
        "        shutil.move(str(sub), outer)\n",
        "    inner.rmdir()\n",
        "\n",
        "print(\"Fixed structure:\", list(outer.iterdir()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xktv23gTL4hl",
        "outputId": "35852508-6f55-4928-a670-9ff14cddcb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed structure: [PosixPath('dataset/fan_off'), PosixPath('dataset/noise'), PosixPath('dataset/lights_off'), PosixPath('dataset/wakeword'), PosixPath('dataset/fan_on'), PosixPath('dataset/lights_on')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, wave\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "WIN_LENGTH  = int(0.025 * SAMPLE_RATE)   # 25 ms\n",
        "HOP_LENGTH  = int(0.010 * SAMPLE_RATE)   # 10 ms\n",
        "N_FFT       = 512\n",
        "N_MELS      = 40\n",
        "N_MFCC      = 13\n",
        "\n",
        "def load_wav_mono_16k(path: Path):\n",
        "    with wave.open(str(path), 'rb') as wf:\n",
        "        assert wf.getframerate() == SAMPLE_RATE, f\"Expected {SAMPLE_RATE}, got {wf.getframerate()}\"\n",
        "        assert wf.getnchannels() == 1, \"Audio must be mono\"\n",
        "        raw = wf.readframes(wf.getnframes())\n",
        "        data = np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0\n",
        "        return data\n",
        "\n",
        "# MFCC helpers (same as before)\n",
        "def hz_to_mel(f): return 2595 * np.log10(1 + f/700)\n",
        "def mel_to_hz(m): return 700 * (10**(m/2595) - 1)\n",
        "\n",
        "def mel_filterbank(sr, n_fft, n_mels, fmin=20, fmax=None):\n",
        "    if fmax is None: fmax = sr/2\n",
        "    mels = np.linspace(hz_to_mel(fmin), hz_to_mel(fmax), n_mels+2)\n",
        "    hz = mel_to_hz(mels)\n",
        "    bins = np.floor((n_fft//2 + 1) * hz / (sr/2)).astype(int)\n",
        "    fb = np.zeros((n_mels, n_fft//2 + 1))\n",
        "    for m in range(1, n_mels+1):\n",
        "        f_m_minus, f_m, f_m_plus = bins[m-1], bins[m], bins[m+1]\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fb[m-1, k] = (k - f_m_minus) / (f_m - f_m_minus)\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fb[m-1, k] = (f_m_plus - k) / (f_m_plus - f_m)\n",
        "    return fb\n",
        "\n",
        "def dct_matrix(M, N):\n",
        "    k = np.arange(N)\n",
        "    m = np.arange(M)[:, None]\n",
        "    d = np.sqrt(2.0/N) * np.cos(np.pi*(k+0.5)*m/N)\n",
        "    d[0] *= 1/np.sqrt(2)\n",
        "    return d\n",
        "\n",
        "MEL_FB = mel_filterbank(SAMPLE_RATE, N_FFT, N_MELS)\n",
        "DCT = dct_matrix(N_MFCC, N_MELS)\n",
        "\n",
        "def framing(y, win_length, hop_length):\n",
        "    n = len(y)\n",
        "    num_frames = 1 + (n - win_length)//hop_length if n >= win_length else 1\n",
        "    frames = np.zeros((num_frames, win_length))\n",
        "    for i in range(num_frames):\n",
        "        start = i*hop_length\n",
        "        end = start+win_length\n",
        "        seg = np.zeros(win_length)\n",
        "        seg[:min(win_length, n-start)] = y[start:min(n, end)]\n",
        "        frames[i] = seg\n",
        "    return frames\n",
        "\n",
        "def mfcc_from_signal(y):\n",
        "    y = np.append(y[0], y[1:] - 0.97*y[:-1])  # pre-emphasis\n",
        "    frames = framing(y, WIN_LENGTH, HOP_LENGTH)\n",
        "    frames *= np.hanning(WIN_LENGTH)\n",
        "    spec = np.fft.rfft(frames, n=N_FFT)\n",
        "    mag = np.abs(spec)\n",
        "    mel = np.dot(mag, MEL_FB.T)\n",
        "    logmel = np.log(np.maximum(mel, 1e-10))\n",
        "    mfcc = np.dot(logmel, DCT.T)\n",
        "    return mfcc.astype(np.float32)\n",
        "\n",
        "# Build database\n",
        "from collections import defaultdict\n",
        "DATASET_DIR = Path(\"dataset\")\n",
        "class_to_files = defaultdict(list)\n",
        "for cls_dir in DATASET_DIR.iterdir():\n",
        "    if cls_dir.is_dir():\n",
        "        for wav in cls_dir.glob(\"*.wav\"):\n",
        "            class_to_files[cls_dir.name].append(wav)\n",
        "\n",
        "mfcc_db = {}\n",
        "for cls, files in class_to_files.items():\n",
        "    feats = [mfcc_from_signal(load_wav_mono_16k(p)) for p in files]\n",
        "    mfcc_db[cls] = feats\n",
        "\n",
        "print(\"Classes loaded:\", {k: len(v) for k,v in mfcc_db.items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3O1I4UAMeDd",
        "outputId": "69720c6b-677c-4ec0-807e-a9e52baf5b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes loaded: {'lights_off': 60, 'wakeword': 60, 'lights_on': 60}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dtw_distance_band(A, B, band=None):\n",
        "    T1, F = A.shape\n",
        "    T2, _ = B.shape\n",
        "    INF = 1e30\n",
        "    D = np.full((T1+1, T2+1), INF, dtype=np.float32)\n",
        "    D[0,0] = 0.0\n",
        "    for i in range(1, T1+1):\n",
        "        j_lo = 1\n",
        "        j_hi = T2\n",
        "        if band is not None:\n",
        "            j_lo = max(1, i - band)\n",
        "            j_hi = min(T2, i + band)\n",
        "        ai = A[i-1]\n",
        "        for j in range(j_lo, j_hi+1):\n",
        "            bj = B[j-1]\n",
        "            cost = np.linalg.norm(ai - bj)\n",
        "            D[i, j] = cost + min(D[i-1,j], D[i,j-1], D[i-1,j-1])\n",
        "    return float(D[T1, T2])\n",
        "\n",
        "def select_k_medoids_dtw(mfcc_list, k=10, band=10, seed=1337):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = len(mfcc_list)\n",
        "    k = min(k, n)\n",
        "    D = np.zeros((n, n), dtype=np.float32)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            d = dtw_distance_band(mfcc_list[i], mfcc_list[j], band=band)\n",
        "            D[i, j] = D[j, i] = d\n",
        "    avg = np.mean(D, axis=1)\n",
        "    medoids = [int(np.argmin(avg))]\n",
        "    while len(medoids) < k:\n",
        "        best_idx, best_gain = None, -1e30\n",
        "        for c in range(n):\n",
        "            if c in medoids: continue\n",
        "            gain = 0.0\n",
        "            for i in range(n):\n",
        "                curr = min(D[i, m] for m in medoids)\n",
        "                newc = min(curr, D[i, c])\n",
        "                gain += (curr - newc)\n",
        "            if gain > best_gain:\n",
        "                best_gain, best_idx = gain, c\n",
        "        medoids.append(best_idx)\n",
        "    medoids.sort()\n",
        "    return medoids, D\n"
      ],
      "metadata": {
        "id": "PwEWmwPWMmqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KEEP_PER_CLASS = 10\n",
        "BAND = 10\n",
        "\n",
        "selected_idxs_by_class = {}\n",
        "for cls, mfcc_list in mfcc_db.items():\n",
        "    idxs, _ = select_k_medoids_dtw(mfcc_list, k=KEEP_PER_CLASS, band=BAND)\n",
        "    selected_idxs_by_class[cls] = idxs\n",
        "    print(f\"{cls}: medoids {idxs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3xDDnQhMrow",
        "outputId": "b52f05bc-0ddd-46dc-fd9a-830ded2293c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lights_off: medoids [0, 2, 4, 14, 15, 24, 25, 30, 31, 40]\n",
            "wakeword: medoids [0, 11, 18, 20, 22, 36, 40, 47, 48, 54]\n",
            "lights_on: medoids [3, 4, 5, 11, 12, 15, 32, 40, 44, 55]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EXPORT_PATH = \"kws_templates.h\"\n",
        "\n",
        "def quantize_mfcc(M):\n",
        "    s = float(np.max(np.abs(M)) + 1e-6)\n",
        "    Q = (M / s * 32767.0).astype(np.int16)\n",
        "    return Q, s\n",
        "\n",
        "class_names = sorted(mfcc_db.keys())\n",
        "templates_meta, blob, scales = [], [], []\n",
        "offset = 0\n",
        "\n",
        "for ci, cls in enumerate(class_names):\n",
        "    mfcc_list = mfcc_db[cls]\n",
        "    for i in selected_idxs_by_class[cls]:\n",
        "        T = mfcc_list[i]\n",
        "        Q, s = quantize_mfcc(T)\n",
        "        h, w = Q.shape\n",
        "        flat = Q.ravel().tolist()\n",
        "        blob.extend(flat)\n",
        "        templates_meta.append((ci, h, w, offset, len(flat)))\n",
        "        scales.append(s)\n",
        "        offset += len(flat)\n",
        "\n",
        "with open(EXPORT_PATH, \"w\") as f:\n",
        "    f.write(\"// Auto-generated: MFCC templates (medoids) for ESP32 DTW\\n\")\n",
        "    f.write(\"#pragma once\\n#include <stdint.h>\\n\\n\")\n",
        "    f.write(f\"#define KWS_N_MFCC {N_MFCC}\\n\")\n",
        "    f.write(f\"static const int KWS_NUM_CLASSES = {len(class_names)};\\n\")\n",
        "    f.write(f\"static const int KWS_NUM_TEMPLATES = {len(templates_meta)};\\n\\n\")\n",
        "\n",
        "    f.write(\"static const int8_t KWS_TEMPL_CLASS_IDX[] = {\")\n",
        "    f.write(\",\".join(str(m[0]) for m in templates_meta))\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "    f.write(\"\\nstatic const uint16_t KWS_TEMPL_FRAMES[] = {\")\n",
        "    f.write(\",\".join(str(m[1]) for m in templates_meta))\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "    f.write(\"\\nstatic const uint16_t KWS_TEMPL_COEFFS[] = {\")\n",
        "    f.write(\",\".join(str(m[2]) for m in templates_meta))\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "    f.write(\"\\nstatic const uint32_t KWS_TEMPL_OFFSET[] = {\")\n",
        "    f.write(\",\".join(str(m[3]) for m in templates_meta))\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "    f.write(\"\\nstatic const uint32_t KWS_TEMPL_LENGTH[] = {\")\n",
        "    f.write(\",\".join(str(m[4]) for m in templates_meta))\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "    f.write(\"\\nstatic const float KWS_TEMPL_SCALE[] = {\")\n",
        "    f.write(\",\".join(f\"{s:.8g}\" for s in scales))\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "    f.write(f\"\\nstatic const int16_t KWS_TEMPL_DATA[{len(blob)}] = {{\")\n",
        "    f.write(\",\".join(str(v) for v in blob))\n",
        "    f.write(\"};\\n\")\n",
        "\n",
        "print(\"Exported:\", EXPORT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTDXzE8kMvhf",
        "outputId": "d904593d-357a-4ab5-c85f-a82eabcd7a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported: kws_templates.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"kws_templates.h\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "v1ftPE8rNcWK",
        "outputId": "81641151-3c00-4fa5-9975-17199a445f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bd0b5bf8-8b53-45b7-b88c-d477c4151c13\", \"kws_templates.h\", 296521)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7: Quick evaluation on held-out clips (vs. medoids) ===\n",
        "import numpy as np\n",
        "\n",
        "BAND = 10  # same Sakoe–Chiba band you used for medoid selection\n",
        "\n",
        "# Build template list: (class_idx, MFCC)\n",
        "templ = []\n",
        "for ci, cls in enumerate(class_names):\n",
        "    for idx in selected_idxs_by_class[cls]:\n",
        "        templ.append((ci, mfcc_db[cls][idx]))\n",
        "\n",
        "# Simple classifier: best DTW (optionally normalized by path length)\n",
        "def dtw_norm(A, B):\n",
        "    D = dtw_distance_band(A, B, band=BAND)\n",
        "    # normalize by total path length to stabilize across durations\n",
        "    return D / (A.shape[0] + B.shape[0])\n",
        "\n",
        "def predict_mfcc(mfcc):\n",
        "    best_c, best_d = None, 1e30\n",
        "    for ci, T in templ:\n",
        "        d = dtw_norm(mfcc, T)\n",
        "        if d < best_d:\n",
        "            best_d, best_c = d, ci\n",
        "    return best_c, best_d\n",
        "\n",
        "# Split: medoids = \"train\", everything else = \"test\"\n",
        "y_true, y_pred, dists = [], [], []\n",
        "cls_to_d = {ci: [] for ci in range(len(class_names))}  # distance distribution per true class\n",
        "\n",
        "for ci, cls in enumerate(class_names):\n",
        "    n = len(mfcc_db[cls])\n",
        "    medoid_set = set(selected_idxs_by_class[cls])\n",
        "    test_indices = [i for i in range(n) if i not in medoid_set]  # held-out\n",
        "    for i in test_indices:\n",
        "        y_true.append(ci)\n",
        "        pred, dist = predict_mfcc(mfcc_db[cls][i])\n",
        "        y_pred.append(pred)\n",
        "        dists.append(dist)\n",
        "        cls_to_d[ci].append(dist)\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "dists = np.array(dists)\n",
        "\n",
        "# Confusion matrix\n",
        "num_classes = len(class_names)\n",
        "cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "for t, p in zip(y_true, y_pred):\n",
        "    cm[t, p] += 1\n",
        "\n",
        "# Accuracy per class and overall\n",
        "per_cls_acc = (cm.diagonal() / cm.sum(axis=1).clip(min=1))\n",
        "overall_acc = (cm.diagonal().sum() / cm.sum().clip(min=1))\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"\\nConfusion matrix (rows=true, cols=pred):\\n\", cm)\n",
        "print(\"\\nPer-class accuracy:\")\n",
        "for ci, cls in enumerate(class_names):\n",
        "    print(f\"  {cls:>12s}: {per_cls_acc[ci]*100:5.1f}%  (n={cm[ci].sum()})\")\n",
        "print(f\"\\nOverall accuracy: {overall_acc*100:5.1f}%  on {cm.sum()} test clips\")\n",
        "\n",
        "# Distance stats to help choose thresholds later\n",
        "print(\"\\nDistance stats by TRUE class (normalized DTW):\")\n",
        "for ci, cls in enumerate(class_names):\n",
        "    arr = np.array(cls_to_d[ci])\n",
        "    if arr.size:\n",
        "        print(f\"  {cls:>12s}: mean={arr.mean():.2f}  median={np.median(arr):.2f}  min={arr.min():.2f}  max={arr.max():.2f}\")\n",
        "    else:\n",
        "        print(f\"  {cls:>12s}: (no held-out clips)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9yXQCB_Ngy2",
        "outputId": "2b6a17c1-6657-4969-8ea0-736234785660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['lights_off', 'lights_on', 'wakeword']\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            " [[43  6  1]\n",
            " [ 2 47  1]\n",
            " [ 0  3 47]]\n",
            "\n",
            "Per-class accuracy:\n",
            "    lights_off:  86.0%  (n=50)\n",
            "     lights_on:  94.0%  (n=50)\n",
            "      wakeword:  94.0%  (n=50)\n",
            "\n",
            "Overall accuracy:  91.3%  on 150 test clips\n",
            "\n",
            "Distance stats by TRUE class (normalized DTW):\n",
            "    lights_off: mean=2.98  median=2.83  min=1.79  max=5.66\n",
            "     lights_on: mean=2.74  median=2.52  min=1.60  max=4.86\n",
            "      wakeword: mean=2.91  median=2.62  min=1.51  max=7.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfZTHEzYOUct"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}